{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:05:09.537241Z",
     "iopub.status.busy": "2025-07-29T07:05:09.536592Z",
     "iopub.status.idle": "2025-07-29T07:05:16.630014Z",
     "shell.execute_reply": "2025-07-29T07:05:16.629447Z",
     "shell.execute_reply.started": "2025-07-29T07:05:09.537205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets analyze the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:05:16.631602Z",
     "iopub.status.busy": "2025-07-29T07:05:16.631197Z",
     "iopub.status.idle": "2025-07-29T07:05:16.635173Z",
     "shell.execute_reply": "2025-07-29T07:05:16.634602Z",
     "shell.execute_reply.started": "2025-07-29T07:05:16.631577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH='/kaggle/input/binary-biplob-art-attack/Artist Classification/train'\n",
    "TEST_PATH='/kaggle/input/binary-biplob-art-attack/Artist Classification/kaggle_test'\n",
    "CLASS_MAPPINGS='/kaggle/input/binary-biplob-art-attack/Artist Classification/class_mapping.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:05:16.636788Z",
     "iopub.status.busy": "2025-07-29T07:05:16.635851Z",
     "iopub.status.idle": "2025-07-29T07:05:16.656126Z",
     "shell.execute_reply": "2025-07-29T07:05:16.655605Z",
     "shell.execute_reply.started": "2025-07-29T07:05:16.636762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Printing the number of folders\n",
    "os.listdir(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T18:04:14.779937Z",
     "iopub.status.busy": "2025-07-26T18:04:14.779722Z",
     "iopub.status.idle": "2025-07-26T18:04:14.795912Z",
     "shell.execute_reply": "2025-07-26T18:04:14.794744Z",
     "shell.execute_reply.started": "2025-07-26T18:04:14.779920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('number of classes', len(os.listdir(TRAIN_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Class mappings folder contains the metadata of the dataset. When submitting, make sure you substitute each label name with its number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:05:20.882011Z",
     "iopub.status.busy": "2025-07-29T07:05:20.881471Z",
     "iopub.status.idle": "2025-07-29T07:05:20.892198Z",
     "shell.execute_reply": "2025-07-29T07:05:20.891224Z",
     "shell.execute_reply.started": "2025-07-29T07:05:20.881989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(CLASS_MAPPINGS) as f:\n",
    "    class_mappings=f.read();\n",
    "\n",
    "print(class_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the images are in a dataset, we use torchvision image folder to load the dataset into from a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:05:26.196205Z",
     "iopub.status.busy": "2025-07-29T07:05:26.195496Z",
     "iopub.status.idle": "2025-07-29T07:05:26.495388Z",
     "shell.execute_reply": "2025-07-29T07:05:26.494689Z",
     "shell.execute_reply.started": "2025-07-29T07:05:26.196179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset=datasets.ImageFolder('/kaggle/input/binary-biplob-art-attack/Artist Classification/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:05:34.510269Z",
     "iopub.status.busy": "2025-07-29T07:05:34.509698Z",
     "iopub.status.idle": "2025-07-29T07:05:34.515356Z",
     "shell.execute_reply": "2025-07-29T07:05:34.514363Z",
     "shell.execute_reply.started": "2025-07-29T07:05:34.510244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:05:45.802629Z",
     "iopub.status.busy": "2025-07-29T07:05:45.802002Z",
     "iopub.status.idle": "2025-07-29T07:05:46.120478Z",
     "shell.execute_reply": "2025-07-29T07:05:46.119729Z",
     "shell.execute_reply.started": "2025-07-29T07:05:45.802600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Enhanced Transforms with Data Augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),          # Larger size for better detail\n",
    "    transforms.RandomResizedCrop(224),      # Random crop for variation\n",
    "    transforms.RandomHorizontalFlip(0.5),   # Horizontal flip\n",
    "    transforms.RandomRotation(15),          # Slight rotation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomGrayscale(p=0.1),      # Occasional grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),             # Center crop for validation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 3. Load datasets with different transforms\n",
    "train_dataset_temp = datasets.ImageFolder(root=TRAIN_PATH, transform=train_transform)\n",
    "val_dataset_temp = datasets.ImageFolder(root=TRAIN_PATH, transform=val_transform)\n",
    "\n",
    "print(f\"Classes: {train_dataset_temp.classes}\")\n",
    "print(f\"Number of classes: {len(train_dataset_temp.classes)}\")\n",
    "\n",
    "# 4. Split indices for consistent train/val split\n",
    "dataset_size = len(train_dataset_temp)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# Create indices for splitting\n",
    "indices = list(range(dataset_size))\n",
    "np.random.seed(42)  # For reproducibility\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# Create datasets using SubsetRandomSampler\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_dataset = Subset(train_dataset_temp, train_indices)\n",
    "val_dataset = Subset(val_dataset_temp, val_indices)\n",
    "\n",
    "# 5. Data loaders with better settings\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    "    num_workers=4,      # Faster data loading\n",
    "    pin_memory=True     # Better GPU transfer\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Batch size: 32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"âœ… Optimized ConvNeXt-Tiny ready!\")\n",
    "print(\"ðŸŽ¯ Expected: Should match or beat EfficientNet-B3's 0.87\")\n",
    "print(\"ðŸ”§ Key changes: Lower LR, higher weight decay, simpler head, cosine scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:05:50.929740Z",
     "iopub.status.busy": "2025-07-29T07:05:50.929016Z",
     "iopub.status.idle": "2025-07-29T07:08:57.161613Z",
     "shell.execute_reply": "2025-07-29T07:08:57.160685Z",
     "shell.execute_reply.started": "2025-07-29T07:05:50.929716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 5. Enhanced Model (convnext_tiny)\n",
    "from torchvision.models import convnext_tiny\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = convnext_tiny(weights='IMAGENET1K_V1')\n",
    "\n",
    "num_features = model.classifier[2].in_features  # Get the correct input features\n",
    "model.classifier[2] = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(num_features, len(train_dataset_temp.classes))  # Direct to classes\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 6. Advanced Loss & optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)  # Label smoothing for better generalization\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)  # AdamW with weight decay\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.0005,          # Half the original LR\n",
    "    weight_decay=0.05,   # 5x higher weight decay\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "# Learning rate scheduler\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1, eta_min=1e-6)\n",
    "\n",
    "\n",
    "# 7. Enhanced Training loop with early stopping\n",
    "epochs = 150  # More epochs\n",
    "best_val_acc = 0.0\n",
    "patience = 7\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Print progress every 50 batches\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Early stopping and model saving\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "        }, 'best_model.pth')\n",
    "        print(f\"  âœ… New best validation accuracy: {val_acc:.2f}%\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  No improvement. Patience: {patience_counter}/{patience}\")\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"Training completed! Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:09:33.136717Z",
     "iopub.status.busy": "2025-07-29T07:09:33.136382Z",
     "iopub.status.idle": "2025-07-29T07:10:01.006150Z",
     "shell.execute_reply": "2025-07-29T07:10:01.005451Z",
     "shell.execute_reply.started": "2025-07-29T07:09:33.136686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model with validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "# Enhanced test transform (same as validation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Test Time Augmentation transforms\n",
    "tta_transforms = [\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),  # Always flip\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomRotation(degrees=5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Enhanced Custom Dataset for test folder\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None, tta_transforms=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_paths = sorted([os.path.join(folder_path, fname) \n",
    "                            for fname in os.listdir(folder_path) \n",
    "                            if fname.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        self.transform = transform\n",
    "        self.tta_transforms = tta_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.tta_transforms:\n",
    "            # Return multiple augmented versions\n",
    "            images = []\n",
    "            for transform in self.tta_transforms:\n",
    "                images.append(transform(img))\n",
    "            return images, img_path\n",
    "        else:\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, img_path\n",
    "\n",
    "# Create dataset with TTA\n",
    "test_dataset = InferenceDataset(TEST_PATH, tta_transforms=tta_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)  # Smaller batch for TTA\n",
    "\n",
    "# Enhanced inference with Test Time Augmentation\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "print(\"Starting inference with Test Time Augmentation...\")\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images_list, paths) in enumerate(test_loader):\n",
    "        batch_predictions = []\n",
    "        \n",
    "        for img_idx in range(len(paths)):\n",
    "            # Get all TTA versions for this image\n",
    "            tta_predictions = []\n",
    "            \n",
    "            for tta_idx in range(len(tta_transforms)):\n",
    "                img = images_list[tta_idx][img_idx].unsqueeze(0).to(device)\n",
    "                output = model(img)\n",
    "                prob = torch.softmax(output, dim=1)\n",
    "                tta_predictions.append(prob.cpu())\n",
    "            \n",
    "            # Average predictions across TTA\n",
    "            avg_prediction = torch.mean(torch.stack(tta_predictions), dim=0)\n",
    "            pred_class = torch.argmax(avg_prediction, dim=1).item()\n",
    "            confidence = avg_prediction[0][pred_class].item()\n",
    "            \n",
    "            results.append({\n",
    "                \"image_id\": os.path.basename(paths[img_idx]),\n",
    "                \"class_id\": pred_class,\n",
    "                \"confidence\": round(confidence, 4)\n",
    "            })\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Processed {batch_idx * test_loader.batch_size}/{len(test_dataset)} images\")\n",
    "\n",
    "# Create submission DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"Generated predictions for {len(df)} images\")\n",
    "print(\"\\nPrediction distribution:\")\n",
    "print(df['class_id'].value_counts().sort_index())\n",
    "\n",
    "# Load sample submission and create final submission\n",
    "submission = pd.read_csv('/kaggle/input/binary-biplob-art-attack/sample_submission.csv')\n",
    "submission['label'] = df['class_id']\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nâœ… Submission saved! Shape: {submission.shape}\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:10:30.645505Z",
     "iopub.status.busy": "2025-07-29T07:10:30.645191Z",
     "iopub.status.idle": "2025-07-29T07:10:31.904142Z",
     "shell.execute_reply": "2025-07-29T07:10:31.903534Z",
     "shell.execute_reply.started": "2025-07-29T07:10:30.645483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize training progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot training loss\n",
    "ax1.plot(train_losses, label='Training Loss', color='blue')\n",
    "ax1.set_title('Training Loss Over Time')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot accuracies\n",
    "epochs_completed = len(train_accuracies)\n",
    "ax2.plot(range(1, epochs_completed + 1), train_accuracies, label='Training Accuracy', color='blue')\n",
    "ax2.plot(range(1, epochs_completed + 1), val_accuracies, label='Validation Accuracy', color='red')\n",
    "ax2.set_title('Model Accuracy Over Time')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_progress.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print final statistics\n",
    "print(f\"ðŸ“Š Training Summary:\")\n",
    "print(f\"  - Epochs completed: {epochs_completed}\")\n",
    "print(f\"  - Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"  - Final training accuracy: {train_accuracies[-1]:.2f}%\")\n",
    "print(f\"  - Final validation accuracy: {val_accuracies[-1]:.2f}%\")\n",
    "\n",
    "# Show prediction confidence distribution\n",
    "df['confidence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:10:38.952874Z",
     "iopub.status.busy": "2025-07-29T07:10:38.952299Z",
     "iopub.status.idle": "2025-07-29T07:10:38.958922Z",
     "shell.execute_reply": "2025-07-29T07:10:38.958369Z",
     "shell.execute_reply.started": "2025-07-29T07:10:38.952850Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission=pd.read_csv('/kaggle/input/binary-biplob-art-attack/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:11:19.858658Z",
     "iopub.status.busy": "2025-07-29T07:11:19.858045Z",
     "iopub.status.idle": "2025-07-29T07:11:19.866431Z",
     "shell.execute_reply": "2025-07-29T07:11:19.865765Z",
     "shell.execute_reply.started": "2025-07-29T07:11:19.858634Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:13:58.990678Z",
     "iopub.status.busy": "2025-07-29T07:13:58.990436Z",
     "iopub.status.idle": "2025-07-29T07:13:58.998478Z",
     "shell.execute_reply": "2025-07-29T07:13:58.997723Z",
     "shell.execute_reply.started": "2025-07-29T07:13:58.990663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:16:44.124812Z",
     "iopub.status.busy": "2025-07-29T07:16:44.124531Z",
     "iopub.status.idle": "2025-07-29T07:16:44.128853Z",
     "shell.execute_reply": "2025-07-29T07:16:44.128098Z",
     "shell.execute_reply.started": "2025-07-29T07:16:44.124792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission['label']=df['class_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T07:16:50.639447Z",
     "iopub.status.busy": "2025-07-29T07:16:50.638931Z",
     "iopub.status.idle": "2025-07-29T07:16:50.645067Z",
     "shell.execute_reply": "2025-07-29T07:16:50.644507Z",
     "shell.execute_reply.started": "2025-07-29T07:16:50.639395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13170129,
     "sourceId": 108642,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
